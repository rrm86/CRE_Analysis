{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' O projeto se divide em análise de timesires e uma tentativa de prever evazão\n",
    "fazendo uso de um algoritmo supervisionado\n",
    "----Passos Time series\n",
    "1 - Baixar o Log no moodle de eventos no moodle para atividades de participação -\n",
    "OK\n",
    "2 - Filtrar os usuário que não são alunos - Excel -pré processamento\n",
    "OK\n",
    "3 - Fazer discretização(IP) - Coluna Rede_Puc\n",
    "OK\n",
    "4 - Adicionar uma coluna referente ao cronograma(unidade 1 e etc)\n",
    "Ok\n",
    "5 - Adicionar coluna com as turmas\n",
    "OK\n",
    "6-  Plotar gráficos com a visualização\n",
    "OK\n",
    "------\n",
    "------ Passos Forecasting\n",
    "1 - Converter a tabela de time series em um data set anterior em um transicional\n",
    "    1.1 - Plotar gráfico com estatśticas gerais de uso -OK\n",
    "    1.2 - Talvez clusterizar os alunos - OK\n",
    "2 - Descobrir quais usuários trancaram a disciplina - Log de atividades CLI\n",
    "OK\n",
    "3 - Descobrir se existe uma data com pico de trancamento\n",
    "4 - Baseado na relação entre data e trancamento definir um intervalo e filtrar o dataset antes desse pico.\n",
    "Fazendo isso imagino que posso descobrir algum padrão nos usuários que trancam. Esse será meu target Y\n",
    "5 - Rodar um random forest\n",
    "6 - avaliar desempenho\n",
    "'''\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from datetime import datetime        \n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series att\n",
    "def rede_puc(turmas):\n",
    "    ip = '139.82'\n",
    "    rede = []\n",
    "    for x in turmas.IP:\n",
    "        if(ip == x[0:6]):\n",
    "            rede.append('S')\n",
    "        else:\n",
    "            rede.append('N')\n",
    "    turmas.insert(1, column='Rede_Puc', value=rede)#Passo 5\n",
    "    return turmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_turmas():\n",
    "    df_ = pd.DataFrame()\n",
    "    frames = [df_]\n",
    "    \n",
    "    for dados_turma in glob.glob('dados/turmas/*'):\n",
    "        grupo = dados_turma[13:-4]# obtem código do grupo\n",
    "        df = pd.read_csv(dados_turma)#lê arquivo\n",
    "        df.insert(3, column='Turma', value=grupo)#insere coluna\n",
    "        print(df.shape)\n",
    "        frames.append(df)\n",
    "    dados = pd.concat(frames)\n",
    "\n",
    "    dados = normaliza_data(dados)\n",
    "    \n",
    "    \n",
    "    return dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_data(dados):\n",
    "    dados.columns = [c.replace(' ', '_') for c in dados.columns]#Troca espaço por underline no cabeçalho\n",
    "    dados.drop_duplicates(keep=False, inplace=True)#limpando dados duplicados\n",
    "    dados['Data'], dados['Hora'] = dados['Hora'].str.split(' ', 1).str#divide a coluna Hora em duas colunas\n",
    "    dados.Data = pd.to_datetime(dados.Data,dayfirst=True)\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series att\n",
    "def obter_unidades(t): \n",
    "    unidades= []\n",
    "    data_unidades = {\n",
    "        'IU1':datetime(2018, 3, 19),\n",
    "        'FU1':datetime(2018, 4, 18),\n",
    "        'IU2':datetime(2018, 4, 18),\n",
    "        'FU2':datetime(2018, 5, 9),\n",
    "        'IU3':datetime(2018, 5, 9),\n",
    "        'FU3':datetime(2018, 5, 23),\n",
    "        'IU4':datetime(2018, 5, 23),\n",
    "        'FU4':datetime(2018, 6, 27)\n",
    "    }\n",
    "\n",
    "    for x in t.Data:\n",
    "        if(data_unidades['IU1'] <= x < data_unidades['FU1']):\n",
    "            unidades.append('unidade_1')\n",
    "        elif(data_unidades['IU2'] <= x < data_unidades['FU2']):\n",
    "            unidades.append('unidade_2')\n",
    "        elif(data_unidades['IU3'] <= x < data_unidades['FU3']):\n",
    "            unidades.append('unidade_3')\n",
    "        elif(data_unidades['IU4'] <= x < data_unidades['FU4']):\n",
    "            unidades.append('unidade_4')\n",
    "        else:\n",
    "            unidades.append('fora_de_epoca')\n",
    "            \n",
    "        \n",
    "    t.insert(1, column='Unidade', value=unidades)\n",
    "    return t\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_periodo_dia(t):\n",
    "    periodo = {\n",
    "        'P1I':'00:00',\n",
    "        'P1F':'04:00',\n",
    "        'P2I':'04:00',\n",
    "        'P2F':'08:00',\n",
    "        'P3I':'08:00',\n",
    "        'P3F':'12:00',\n",
    "        'P4I':'12:00',\n",
    "        'P4F':'16:00',\n",
    "        'P5I':'16:00',\n",
    "        'P5F':'20:00',\n",
    "        'P6I':'20:00',\n",
    "        'P6F':'24:00'\n",
    "    }\n",
    "    periodo_list = []\n",
    "    for x in t.Hora:\n",
    "        if (periodo['P1I'] <= x < periodo['P1F']):\n",
    "            periodo_list.append('1')\n",
    "        elif(periodo['P2I'] <= x < periodo['P2F']):\n",
    "            periodo_list.append('2')\n",
    "        elif(periodo['P3I'] <= x < periodo['P3F']):\n",
    "            periodo_list.append('3')\n",
    "        elif(periodo['P4I'] <= x < periodo['P4F']):\n",
    "            periodo_list.append('4')\n",
    "        elif(periodo['P5I'] <= x < periodo['P5F']):\n",
    "            periodo_list.append('5')\n",
    "        elif(periodo['P6I'] <= x < periodo['P6F']):\n",
    "            periodo_list.append('6')\n",
    "\n",
    "        \n",
    "    t.insert(1, column='Periodo', value=periodo_list)\n",
    "    return t\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "turmas = obter_turmas() \n",
    "turmas = rede_puc(turmas)\n",
    "turmas = obter_unidades(turmas)\n",
    "turmas = obter_periodo_dia(turmas)\n",
    "turmas.Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas.to_csv('turmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "turmas['Unidade'].value_counts().sort_index().plot.bar();\n",
    "turmas['Unidade'].value_counts().sort_index().plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(turmas['Unidade']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas['Periodo'].value_counts().sort_index().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=turmas['Periodo'],data=turmas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recursos = turmas['Contexto_do_Evento'].value_counts().plot.bar(figsize=(24, 12))\n",
    "recursos.set_title(\"Recursos\", fontsize=20)\n",
    "turmas['Contexto_do_Evento'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas['Turma'].value_counts().sort_index().plot.bar();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=turmas['Turma'],data=turmas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas['Rede_Puc'].value_counts().sort_index().plot.bar();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parte 2\n",
    "turmas2=turmas.groupby('Nome_completo')['Contexto_do_Evento'].value_counts().sort_index().unstack().fillna(0)#tranformando timesires em data frame\n",
    "turmas2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import decomposition\n",
    "def cluster(t):\n",
    "    data=t\n",
    "    kmeans = KMeans(n_clusters = 8, init = 'k-means++')\n",
    "    kmeans = kmeans.fit(data)\n",
    "    plot_2D_cluster(data,kmeans)\n",
    "    plot_3D_cluster(data,kmeans)\n",
    "    return kmeans\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_cluster(data,kmeans):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = 2\n",
    "    X_reduced = pca.fit_transform(data)\n",
    "    values = kmeans.cluster_centers_.squeeze()\n",
    "    labels = kmeans.labels_\n",
    "    centroid = pca.fit_transform(values)\n",
    "    centroid_label = set(labels) \n",
    "    plt.scatter(X_reduced[:,0],X_reduced[:,1],c=labels,cmap='tab20')\n",
    "    #plt.scatter(centroid[:,0],centroid[:,1],c=range(0,len(centroid_label)),cmap='Set1',marker='D')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def plot_3D_cluster(data,kmeans):\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    \n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = 3\n",
    "    X_reduced = pca.fit_transform(data)\n",
    "    values = kmeans.cluster_centers_.squeeze()\n",
    "    labels = kmeans.labels_\n",
    "    centroid = pca.fit_transform(values)\n",
    "    centroid_label = set(labels) \n",
    "    \n",
    "    ax.scatter(X_reduced[:,0],X_reduced[:,1],X_reduced[:,1] , c=labels,cmap='tab20')\n",
    "    #ax.scatter(centroid[:,0],centroid[:,1],centroid[:,2],c=range(0,len(centroid_label)),cmap='Set1',marker='D')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster(turmas2.iloc[:, :,].values)\n",
    "#3-5-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turmas2.to_csv('teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_csv('teste.csv')\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = new.describe()\n",
    "describe.to_csv('metricas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "trancamento = pd.read_csv('dados/excluded.csv')#log com os dados de trancamento\n",
    "\n",
    "\n",
    "lt = new['Nome_completo'].tolist()\n",
    "\n",
    "tranc = trancamento['Nome']\n",
    "print(len(tranc))\n",
    "\n",
    "remove = []\n",
    "        \n",
    "for i in range(0,len(tranc)):\n",
    "    if tranc[i] not in lt:\n",
    "        remove.append(i)\n",
    "\n",
    "\n",
    "trancamento.drop(trancamento.index[remove], inplace=True)#obtem a lista com os usuários que tracaram-6TA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trancamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trancamento = normaliza_data(trancamento)\n",
    "trancamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trancamento = obter_unidades(trancamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trancamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trancamento.to_csv('trancamento_final.csv')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
